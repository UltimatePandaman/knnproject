{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce9eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notes: Zbyněk Lička\n",
    "## Changes:\n",
    "## 1. completely revamped the code to save tuples of paths to speaker recordings\n",
    "## For reference, check the original implementation: https://github.com/yl4579/StarGANv2-VC/blob/main/Data/VCTK.ipynb\n",
    "## Additionally non-original comments are denoted by a double hash (##)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769a7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: http://speech.ee.ntu.edu.tw/~jjery2243542/resource/model/is18/en_speaker_used.txt\n",
    "# Source: https://github.com/jjery2243542/voice_conversion\n",
    "\n",
    "speakers = ['p225', 'p226']\n",
    "directory = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9302fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if directories exist\n",
    "for speaker in speakers:\n",
    "    if not os.path.exists(os.path.join(*[directory, speaker])):\n",
    "        print(f\"Directory: {speaker} doesn't exist in converted train data!\")\n",
    "for speaker in speakers:\n",
    "    if not os.path.exists(os.path.join(*[directory, speaker])):\n",
    "        print(f\"Directory: {speaker} doesn't exist in converted eval data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0ca022",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "train_speaker_datapath = directory\n",
    "\n",
    "speaker_a_file_list = []\n",
    "for dirpath,_,filenames in os.walk(os.path.join(train_speaker_datapath, speakers[0])):\n",
    "        for f in filenames:\n",
    "            speaker_a_file_list.append(os.path.join(dirpath, f))\n",
    "speaker_b_file_list =[]\n",
    "for dirpath,_,filenames in os.walk(os.path.join(train_speaker_datapath, speakers[1])):\n",
    "        for f in filenames:\n",
    "            speaker_b_file_list.append(os.path.join(dirpath, f))\n",
    "\n",
    "\n",
    "num_samples = min(len(speaker_a_file_list), len(speaker_b_file_list))\n",
    "np.random.shuffle(speaker_a_file_list)\n",
    "np.random.shuffle(speaker_b_file_list)\n",
    "speaker_a_file_list = speaker_a_file_list[:num_samples]\n",
    "speaker_b_file_list = speaker_b_file_list[:num_samples]\n",
    "\n",
    "## Train, validation and test split\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "train_a = speaker_a_file_list[:int(train_split*num_samples)]\n",
    "train_b = speaker_b_file_list[:int(train_split*num_samples)]\n",
    "\n",
    "val_a = speaker_a_file_list[int(train_split*num_samples):int((train_split+val_split)*num_samples)]\n",
    "val_b = speaker_b_file_list[int(train_split*num_samples):int((train_split+val_split)*num_samples)]\n",
    "\n",
    "eval_a = speaker_a_file_list[int((train_split+val_split)*num_samples):]\n",
    "eval_b = speaker_b_file_list[int((train_split+val_split)*num_samples):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8559497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the train, val and test data list\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "eval_data_list = []\n",
    "\n",
    "for i in range(len(train_a)):\n",
    "    train_data_list.append({'speaker_a':train_a[i], 'speaker_b':train_b[i]})\n",
    "\n",
    "for i in range(len(val_a)):\n",
    "    val_data_list.append({'speaker_a':val_a[i], 'speaker_b':val_b[i]})\n",
    "\n",
    "for i in range(len(eval_a)):\n",
    "    eval_data_list.append({'speaker_a':eval_a[i], 'speaker_b':eval_b[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5c9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "## This part was mostly kept intact\n",
    "## only added test_list.txt for evaluation and changed the output\n",
    "file_str = \"\"\n",
    "for k in train_data_list:\n",
    "    ## changed the output to speaker_a|speaker_b filepaths\n",
    "    file_str += k['speaker_a'] + \"|\" + k['speaker_b'] + '\\n'\n",
    "text_file = open(os.path.join(train_speaker_datapath,\"train_list.txt\"), \"w\")\n",
    "text_file.write(file_str)\n",
    "text_file.close()\n",
    "\n",
    "file_str = \"\"\n",
    "for k in val_data_list:\n",
    "    file_str += k['speaker_a'] + \"|\" + k['speaker_b'] + '\\n'\n",
    "text_file = open(os.path.join(train_speaker_datapath,\"val_list.txt\"), \"w\")\n",
    "text_file.write(file_str)\n",
    "text_file.close()\n",
    "\n",
    "# reference\n",
    "file_str = \"\"\n",
    "for k in eval_data_list:\n",
    "    file_str += k['speaker_a'] + \"|\" + k['speaker_b'] + '\\n'\n",
    "text_file = open(os.path.join(train_speaker_datapath, \"test_list.txt\"), \"w\")\n",
    "text_file.write(file_str)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
